```{r setup, include=FALSE,message=FALSE,warning=FALSE}
# OPTIONS -----------------------------------------------
knitr::opts_chunk$set(echo = TRUE, 
                      warning=FALSE, 
                      message = FALSE)

# PACKAGES-----------------------------------------------
# Tutorial packages
library(vembedr)
library(skimr)
library(yarrr)
library(RColorBrewer)
library(GGally) 
library(tidyverse)
library(plotly)
library(readxl)
library(rvest)
library(biscale)
library(tidycensus)
library(cowplot)
library(units)
library(olsrr)

data("HousesNY", package = "Stat2Data")



```

# Regression {#T8_regression}

Now we will fit our first regression model.

## "Standard" regression output {#T8_lmbasics}

The command to do this is `lm()` e.g. linear model.

```{r,eval=FALSE}
output <- lm(y_column ~ x_column,data=tablename)
output
```

NOTE, THE WEIRD \~ SYMBOL. This means "depends on"/"is modelled by" and it's how we tell R what the response variable is. E.g. in y=mx+c, y depends on x, or y is modelled/predicted by x.

For example for the NYHouses dataset, if I wanted to create a model of the Price and Lot columns to see if Lot size could predict house sales price, then I would type.

```{r}
# response = Price, predictor = Lot size
Model1.lm <- lm(Price ~ Lot,data=HousesNY)
Model1.lm
```

So we are saying here that the equation is

Expected_Average_Price = -0.5749\*Lot_Size + 114.0911

E.g. the average expected price house with no Lot/Garden is 114.09




### Printing out the equation

You can also directly get the code for the model equation by the equatiomatic package

```{r,eval=FALSE}
# YOU MIGHT NEED TO INSTALL THIS PACKAGE (SEE THE TUTORIAL)
library(equatiomatic)
extract_eq(Model1.lm,use_coefs=FALSE)
```

To make it print out directly, put "asis=TRUE" as a code chunk option e.g. this code

```{r, eqn, echo=FALSE,fig.cap="See the asis in the top, this prints the output directly when you knit"}
knitr::include_graphics('./index_images/Tut7_extract_eq.png')
```

Turns into this:

```{r,asis=TRUE}
library(equatiomatic)
extract_eq(Model1.lm,use_coefs=FALSE)
```

You can also look at the summary by looking at the summary command:

```{r}
summary(Model1.lm)
```

In both cases, we have an estimate of the intercept (0.6386) and of the gradient (-13.8103). We will discuss the other values in later labs/lectures.

Now let's see how to add the regression line to our scatterplot. We can do this using `abline(REGRESSION_VARIABLE)`, where regression_variable is the name of the variable you saved the output of lm to. For example.

```{r}
plot(HousesNY$Price ~ HousesNY$Lot)
abline(lm(Price ~ Lot,data=HousesNY),col="blue",lwd=1) 

```

For more professional plots, see the scatterplots tutorial

<br>

## "Better" OLSRR regression output

If you want a different way of seeing the same output, you can use the `ols_regress()` command inside the `olsrr` package.

```{r}
library(olsrr)
Model1.lm.ols <- ols_regress(Model1.lm)
Model1.lm.ols
```

The ols_regress command produces beautiful output, but sometimes it doesn't work well with other commands. So I tend to run a lm command at the same time to have both available.

<br>

### Errors

Sometimes, this command can produce a weird error:

```{r, olsrr.error, echo=FALSE,fig.cap="This is probably because you loaded the moderndive package"}
knitr::include_graphics('./index_images/Tut7_OLSRR.png')
```

This is probably because you loaded the moderndive package. They do not play nicely together. Save your work, restart R and **do not run any line that says library(moderndive)!**.
